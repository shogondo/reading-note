# Chapter 17. Best practices for developing apps

この章のテーマ

* それぞれのリソースが一般的なアプリケーションを実行する上でどのように使われるか
* マシン間での移動がほとんど発生しないアプリと、再配置が頻繁に行われる Pod として稼働しているアプリの違い
* マルチコンポーネントアプリケーション (マイクロサービス) が特定の起動順序に依存すべきでないことを理解する
* Pod の初期化やメインコンテナの開始を遅延させるために利用することができる init コンテナの導入
* コンテナのライフサイクルフックについて
* Kubernetes コンポーネントの分散特性と結果整合性モデルについて
* イメージのサイズを小さく保ち、アノテーションや多次元ラベルによってアプリを管理しやすくする
* マルチノードのクラスタにデプロイする前にローカルでアプリを開発する方法

## 17.1. BRINGING EVERYTHING TOGETHER

* 実際の (一般的な) アプリケーションがどのように構成されているのかを示したのが下図。
* ![17fig01_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig01_alt.jpg)

**訳を記載するか口頭にするかは要検討**

## 17.2. UNDERSTANDING THE POD’S LIFECYCLE

* Pod で実行されるアプリは VM 内で実行されるアプリと似たようなものではあるが、大きな違いもある。
* その一つが、Pod は再配置やスケールインによっていつでも停止し得るという点。

### 17.2.1. Applications must expect to be killed and relocated

* VM で実行されているアプリがマシン間を移動することは滅多にない。
* 移動する場合は運用担当がアプリを移動させて、アプリの再設定は手動でのチェックを行うことになる。
* 一方、Kubernetes では、アプリは頻繁かつ自動的に再配置され、手動で再設定や稼働チェックを行うこともない。
* つまり、開発者はアプリが頻繁に再配置されても問題ないようにする必要がある。

#### Expecting the local IP and hostname to change

* Pod が再配置 (古い Pod が停止して新しい Pod が起動) されると、IP アドレスだけでなく Pod 名やホスト名も変わることになる
* アプリがステートレスであれば通常問題ないが、ステートフルの場合は影響なしに再配置に対応することはできない
* その場合は StatefulSet を使う (新しい Pod が起動しても以前と同じホスト名で同じボリュームがマウントされる) **要確認**
* それでも IP は変わるので、IP は代わり得るという前提でアプリを作成する必要がある。

#### Expecting the data written to disk to disappear

* Pod がディスクにデータを書き込む場合、書き込み先に永続ストレージをマウントしないと Pod の再配置によってデータが参照できなくなる
* 再配置される場合だけでなく、Pod が生きている間にもデータが消える可能性がある。
* プロセスクラッシュ、liveness probe がエラーを返す、OOM Killer にプロセスが kill されるなどの理由で、個々のコンテナが再起動される可能性があり、これが発生すると Pod の再配置は発生しなくてもコンテナが新たに作成され、書き込み可能レイヤーが新しくなる。
* ![17fig02_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig02_alt.jpg)
* それを防ぎたい場合には少なくとも Pod スコープのボリュームを使う必要がある **要確認**
* Pod が生きていればボリュームを使い続けられるので、コンテナが再起動した場合でも前のデータが残る
* ![17fig03_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig03_alt.jpg)
* ただし、ボリュームのデータの破損に起因してコンテナがクラッシュするようなケースだと、継続的にコンテナがクラッシュし続けることになってしまう。
* コンテナが再起動しても前のファイルを保持し続けるようにするのはデメリットもあるので、使用するかどうかは慎重に検討すべき。

### 17.2.2. Rescheduling of dead or partially dead pods

* Pod 内のコンテナがクラッシュを続けると Kubelet が再起動を繰り返す。再起動までの時間は指数関数的に長くなっていき、最長で 5 分。
* 再起動までの間、実質的に Pod は死んでいることになる。
*ReplicaSet は Pod 数がマニフェストと一致するかどうかしか感知しない (Pod が死んでいるかどうかは気にしない) ため、ReplicaSet で Pod が起動されていたとしてもこのような Pod は再スケジューリングされない。
* ![17fig04_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig04_alt.jpg)
* **回避策は?**

### 17.2.3. Starting pods in a specific order

#### Understanding how pods are started

* 複数 Pod で構成されるアプリケーションを Kubernetes にデプロイする際に、Pod に依存関係を持たせる (特定の Pod が使用可能な状態になってから別の Pod を起動する) ような方法は提供されていない
* API サーバーはマニフェストを上から順に処理し、その順序で etcd に書き込まれるが、Pod も上から順番に起動されるという保証はない
* 前提条件が満たされるまで Pod のメインコンテナが起動しないようにすることが可能 = init コンテナ

#### Introducing Init Containers

* init コンテナは Pod を初期化するためのもの
* Pod のボリュームにデータを書き込み、それをメインコンテナでマウントして使用する
* 複数の init コンテナを持たせることができる。その場合順番に実行されて最後のコンテナが完了したらメインのコンテナが起動する => 特定の前提条件を満たすまで、メインコンテナの実行を遅延させることが可能

#### Adding an Init Container to a pod

**コード、試す**

#### Best practices for handling inter-pod dependencies

* Pod 実行中に依存先がオフラインになる可能性もあるので、アプリ起動時点で依存している全てのサービスが稼働していなければならないようなコードにはしない方がベター
* アプリは依存先が not ready であることを内部的に処理できる必要がある
* readiness probe を行い、依存先が not ready で処理ができないなら自身も not ready であることを Kubernetes に認識されるようにすべき

### 17.2.4. Adding lifecycle hooks

* 定義可能なライフサイクルフック
  * Post-start hooks
  * Pre-stop hooks
* ライフサイクルフックは各コンテナの起動と停止の際に実行される。
* liveness や radiness probe のように以下ができる
  * コンテナ内でコマンドを実行する
  * URL に対して HTTP GET する

#### Using a post-start container lifecycle hook

* Post-start フックはコンテナのメインプロセス開始直後に実行される。
* コードに手を加えることなくアプリ起動時の追加処理が可能。
* フックの処理はメインプロセスと並行して実行される (メインプロセスが完全に起動するのを待たない)。
* フックが完了するまで、コンテナーは ContainerCreating という理由で Waiting 状態のままになるので、ステータスは「実行中」ではなく「保留中」となる。
* フックが実行に失敗した場合、またはゼロ以外の終了コードを返した場合、メインコンテナは強制終了される。
**サイドのコンテナで失敗しても？**

**コード, 試す**

* シェルコマンドを直接マニフェストに書くこともできるが、コンテナイメージにフック用のシェルスクリプトやバイナリを格納しておくのが一般的
* フックプロセスが stdout にログを書き込んでもどこにも出力されない
* Pod のイベントに FailedPostStartHook が出力されていることで、フックに失敗したのを知ることはできる
* ファイルにログを書き込めば後からログを確認することは可能だが、コンテナが再起動されるとログを出力したファイルも消えてしまうので、emptyDir をマウントしてそこにログを書き込むといった工夫が必要。

#### Using a pre-stop container lifecycle hook

* Pre-stop はコンテナが終了する直前に実行される。
* Kubelet は Pre-stop フックを実行してから SIGTERM をメインプロセスに送る
**コード,試す**
* Pre-stop フックの実行が成功しても失敗しても、コンテナは終了する。
* フックが失敗した場合、イベントに FailedPreStopHook が記録されるが、その後すぐに Pod が削除されて失敗に気づかない可能性がある

#### Understanding that lifecycle hooks target containers, not pods

* Pre-stop フックは Pod ではなくコンテナのライフサイクルに関連づけられていることに注意。
* Pod 終了時に何らかの処理を実行するために Pre-stop フックを使用すべきではない。
* コンテナは Pod が停止するタイミング以外でも停止する可能性があり (多くの場合、liveness probe の失敗)、Pod が生きている間に Pre-stop フックが複数回実行され得る。

### 17.2.5. Understanding pod shutdown

* Pod の停止は、API サーバーを介して Pod リソースが削除されたことをトリガーに始まる (この時点では deletionTimestamp が設定されるだけでリソース自体はまだ存在している)。
* Kubelet が Pod の停止が必要であることを検知すると、Pod 内のコンテナの停止が行われる。
* コンテナ停止の流れ
  1. Pre-stop フックを実行してその終了を待つ
  2. コンテナのメインプロセスに SIGTERM を送る
  3. コンテナが終了するか、終了猶予期間 (termination grace period) が経過するまで待つ
  4. Graceful shutdown が行われなければ SIGKILL を送る
* ![17fig05_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig05_alt.jpg)
* spec.terminationGracePeriodSeconds で終了猶予期間を設定できる (デフォルト 30)。
* Pod の全てのコンテナが終了すると Kubelet は API サーバーに通知し、Pod リソースが完全に削除される。

#### Implementing the proper shutdown handler in your application

* 例えば、分散データストアをマルチ Pod アプリとしてデプロイしており、Pod が 1 つ停止する際にデータロストを防ぐために残りの Pod にデータを移行する必要がある、という場合、SIGTERM や Pre-stop フックでのデータ移行はお勧めしない
  1. コンテナ終了が Pod 全体の終了を意味するわけではない
  2. プロセスが強制終了される前にデータ移行処理が完了する保証がない
* 2 は終了猶予期間内で処理が終わらなかった場合だけでなく、例えばコンテナのシャットダウンシーケンスの途中でノードが落ちた場合にも発生し得る (ノードが再起動しても、その後シャットダウン処理が継続して行われることはない)
*

#### Replacing critical shut-down procedures with dedicated shut-down procedure pods

* 絶対に最後まで実行する必要がある重要なシャットダウン手順が最後まで実行されるようにするにはどうすればよいか
* 1 つの解決策は、アプリ終了時に、データ移行を行う新しい Pod を実行するための Job リソースを新たに作成すること。
* ただ、アプリが Job リソースの作成を実行しようとしたまさにその時にノードが落ちる可能性もあり、Job リソースが毎回必ず作成される保証はない
* このような場合は、孤立したデータの有無をチェックし続ける常駐 Pod や CronJob を用意して対応する

## 17.3. ENSURING ALL CLIENT REQUESTS ARE HANDLED PROPERLY

### 17.3.1. Preventing broken client connections when a pod is starting up

* Pod が開始されると、Pod のラベルに一致するラベルセレクタを持っている全てのサービスにエンドポイントとして追加される
* readiness probe を使用しない場合、Pod は常に Ready 状態と見なされるので、kube-proxy がノードの iptables を更新し、すぐにリクエストがルーティングされる状態となる (コンテナが実際には接続可能な状態でないのであれば「接続が拒否されました」という類のエラーになる)
* これを防ぐには、コンテナがリクエストを処理できる状態になってから readiness probe に成功を返すようにする必要がある (例えば HTTP GET probe をアプリの URL に向ける)

### 17.3.2. Preventing broken connections during pod shut-down

それでは、ポッドが削除されてそのコンテナーが終了したときに、ポッドのもう一方の端で何が起こるかを見てみましょう。 SIGTERMシグナルを受信した直後（またはプレストップフックが実行されたとき）に、ポッドのコンテナがどのようにクリーンにシャットダウンを開始するかについてはすでに説明しました。 しかし、それによってすべてのクライアント要求が正しく処理されるようになりますか？

アプリが終了シグナルを受信したときの動作はどのようになりますか？ それは要求を受け入れ続けるべきですか？ すでに受信されているがまだ完了していない要求についてはどうですか。 持続的なHTTP接続についてはどうでしょうか。それはリクエストの間にあるかもしれませんが、開いています（接続にアクティブなリクエストが存在しない場合）。 これらの質問に答える前に、Podが削除されたときにクラスター全体に広がる一連のイベントを詳細に調べる必要があります。

#### Understanding the sequence of events occurring at pod deletion

* API サーバーが Pod の削除要求を受け取ると、etcd 内の状態を変更し、Watcher に削除を通知する
* Endpoint に登録されている Pod の削除が要求された場合の流れが下図。A が Kubelet への通知のシーケンス、B が Endpoint への通知のシーケンスを表す
* ![17fig07_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig07_alt.jpg)
* Kubelet は Pod 終了通知を受けると Pod のシャットダウンシーケンスを開始する (Pre-stop フックの実行、SIGTERM/SIGKILL 送信)。
* アプリが SIGTERM を受けてすぐにクライアントからのリクエストの受付を停止するような場合、その後接続を試みるクライアントは Connection Refused になる
* Pod 削除は API サーバーから Kubelet に直接通知されるので、この状態になるまでの時間は比較的短い。
* 一方、B のシーケンスでは、Endpoint コントローラが Pod 削除通知を受け取り、Pod が属する全てのサービスのエンドポイントからその Pod を削除するよう API サーバーにリクエストする
* API サーバーはリクエストを受け取ると、Endpoint の変更を監視している Watcher に通知を行う
* kube-proxy はこの変更を監視しており、通知をうけて iptables を更新する
* この iptables の変更により新しい接続が削除された Pod にルーティングされなくなる (ただし、確立済みの接続には影響しない)
* A よりも B の方が時間がかかる可能性があり、Pod のシャットダウンシーケンスが開始された後も、Pod はクライアントからのリクエストを受ける可能性がある
* ![17fig08_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig08_alt.jpg)

#### Solving the problem

* この問題は、一見 readiness probe を使えば対処できそうに見える (SIGTERM をうけたらすぐに readiness probe が失敗するようにするなど)
* しかし、実際には Endpoint コントローラは Pod 削除通知を受け取るとすぐに Endpoint から Pod を削除し、それ以後 readiness probe の結果は考慮しなくなるので、readiness probe を失敗させても何の影響もない
* この問題に対処するには、SIGTERM を受信した後も、リクエストがルーティングされる可能性がある間 (iptables ルールが更新されるまで、もしくは iptables を使わずに直接 Pod にリクエストをルーティングする Ingress コントローラからリクエストがルーティングされなくなるまで) はリクエストを受け入れ続け、リクエストが Pod にルーティングされなくなったことが通知されるまで待つ必要がある
* しかしながら、分散システムであるがゆえに、各コンポーネントが Pod をシャットダウンして問題ないという状態になるまで待ち続けるのは現実的ではない
* 合理的な方法は、各コンポーネントが処理を終えられるように「十分長い間」待つこと。
* どのくらいが十分なのかは一概には言えず、問題を完全に解決することはできないが、5 から 10 秒待つだけでも UX は改善されるだろう

#### Wrapping up this section

* まとめると、アプリを正しくシャットダウンするには
  * 数秒待ってから、新しい接続の受け入れを停止する
  * 要求の途中ではないすべてのキープアライブ接続を閉じる
  * アクティブな要求がすべて終了するのを待つ
  * それから完全にシャットダウンする
* ![17fig09_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig09_alt.jpg)
* 全てのアプリで上記をやる必要がある (やる価値がある) かは開発者が判断することだが、少なくともこのような Pre-stop フックを追加するのは良い方法

```
lifecycle:
  preStop:
    exec:
      command:
      - sh
      - -c
      - "sleep 5"
```

## 17.4. MAKING YOUR APPS EASY TO RUN AND MANAGE IN KUBERNETES

### 17.4.1. Making manageable container images

* コンテナイメージ作成時に、アプリのバイナリとそれに必要なライブラリを追加するという方法を取ることも、アプリと OS のファイルシステム全体をイメージ化するという方法をとることもできる。
* だが、通常は OS のファイルシステム全体を含める必要はない。無駄にイメージのサイズが大きくなるだけ。
* ただし、最小限のイメージの場合デバッグが難しくなる
* 何を含めて何を含めないかのさじ加減は開発者自身で判断すべき

### 17.4.2. Properly tagging your images and using imagePullPolicy wisely

* Pod マニフェストで latest タグを使ってイメージを参照していると、個々の Pod レプリカがどのイメージを実行しているのか特定できなるという問題がある
* 新しいイメージを latest タグ付きで push すると、古いバージョンのイメージを再 push しない限り以前のバージョンにロールバックできなくなる
* latest ではなく適切なバージョン指定タグを使うことは、プロダクション環境では必須
* 可変タグを使う (同じタグに変更を push する) 場合は imagePullPolicy フィールドを Always に設定する必要がある **要確認**
* ただし、この場合、新しい Pod がデプロイされるたびにコンテナランタイムがイメージレジストリにアクセスしてイメージの変更チェックを行うので、Pod の起動が遅くなる。また、レジストリに接続できないと Pod が起動できなくなる

### 17.4.3. Using multi-dimensional instead of single-dimensional labels

* Pod だけでなく全てのリソースにラベルをつけるべき。
* また、複数のラベルをつけ、色々なディメンジョンでリソースのフィルタリングができるようにした方が良い。
* ラベルには、このようなものを含めるのがよい。これにより、リソースを個別にではなくグループで管理し、各リソースがどこに属しているのかを簡単に確認できるようになる。
  * リソースが属するアプリケーションやマイクロサービスの名前
  * アプリケーション層 (フロントエンド、バックエンドなど)
  * 環境 (開発、QA、ステージング、プロダクションなど)
  * バージョン
  * リリースの種類 (Stable、Canary、Blue/Green）
  * テナント (ネームスペースを使用せずに、テナントごとに別々のポッドを実行している場合)
  * シャードシステム用のシャード

### 17.4.4. Describing each resource through annotations

* リソースに追加情報を追加する際には Annotation を使用する
* 少なくともリソースの説明と、担当者の連絡先情報を含む Annotation をつける
* マイクロサービスアーキテクチャでは、Pod に依存しているサービス名のリストを Annotation することで、Pod 間の依存関係を表すことができる

### 17.4.5. Providing information on why the process terminated

* ログには必要なデバッグ情報を全て含めるべき
* トリアージをさらに簡単にするために、プロセスがコンテナのファイルシステム内の特定のファイルに終了メッセージを書き込むようにするとよい
* このファイルの内容は、コンテナが終了したときに Kubelet によって読み取られ、kubectl describe podの出力に表示されるようになり、コンテナログを見なくてもアプリが終了した理由を確認できるようになる
* デフォルトでは /dev/termination-log だが、マニフェストの terminationMessagePath で別のファイルを指定可能

```
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-termination-message
spec:
  containers:
  - image: busybox
    name: main
    terminationMessagePath: /var/termination-reason
    command:
    - sh
    - -c
    - 'echo "I''ve had enough" > /var/termination-reason ; exit 1'
```

* このポッドを実行すると、すぐにポッドのステータス がCrashLoopBackOff として表示され、`kubectl describe` を使用すると、ログを調べなくてもコンテナが停止した理由がわかる

```
$ kubectl describe po
Name:           pod-with-termination-message
...
Containers:
...
    State:      Waiting
      Reason:   CrashLoopBackOff
    Last State: Terminated
      Reason:   Error
      Message:  I've had enough
      Exit Code:        1
      Started:          Tue, 21 Feb 2017 21:38:31 +0100
      Finished:         Tue, 21 Feb 2017 21:38:31 +0100
    Ready:              False
    Restart Count:      6
```

### 17.4.6. Handling application logs

* アプリのログを参照したい場合、ログが標準出力に書き込まれているのであれば、 `kubectl logs` で簡単にログを参照可能。
* ファイルに出力されているのであれば `kubectl exec <pod> cat <logfile>` のようにログファイルを参照する。

#### Copying log and other files to and from a container

* `kubectl cp` コマンドを使用して、ログファイルをローカルマシンにコピーすることも可能。

```
$ kubectl cp foo-pod:/var/log/foo.log foo.log
```

* ローカルマシンからポッドにファイルをコピーするには、2 番目の引数にポッドの名前を指定する

```
$ kubectl cp localfile foo-pod:/etc/remotefile
```

#### Using centralized logging

* Pod のログは Pod が存在する間だけ参照でき、Pod が削除されるとログも削除されてしまうので、プロダクション環境ではログ管理ソリューションを導入することになるだろう。
* Kubernetes 自体は、このような仕組みを提供していない。
* はログ管理ソリューションについてはこの本の範囲を超えるが、ElasticSearch、Logstash や FluendD、Kibana を使った仕組みがよく利用される
* ![17fig10_alt](https://learning.oreilly.com/library/view/kubernetes-in-action/9781617293726/17fig10_alt.jpg)

## 17.5. BEST PRACTICES FOR DEVELOPMENT AND TESTING

### 17.5.1. Running apps outside of Kubernetes during development

* Kubernetes クラスタで実行するアプリを開発しているからといって、開発中も Kubernetes で実行させる必要があるのか？ => No. マイナーチェンジのたびにアプリを作成してからコンテナイメージを作成し、それをレジストリにプッシュしてからポッドを再デプロイする、というのは開発が遅くなり面倒

#### Connecting to backend services

* プロダクション環境でアプリがバックエンドサービス
本番環境で、アプリが BACKEND_SERVICE_HOST および BACKEND_SERVICE_PORT 環境変数を使用してバックエンドサービスを探して接続しているような場合には、開発環境で手動でこれらの環境変数を指定することがで対応できる
* Kubernetes クラスタ内でこのサービスが実行されているのであれば、NodePort または LoadBalancer タイプのサービスに変更し、一時的にサービスに外部からアクセスできるようにすることも可能。

#### Connecting to the API server

* アプリが Kubernetes API サーバーへのアクセスを必要とする場合、`kubectl cp` でServiceAccount のシークレットをローカルに持ってくることで、API サーバーにアクセス可能 (API サーバーはアクセス元がクラスタ内にあるかどうかは関知しない)。
* アンバサダーコンテナを使っている場合は、ローカルマシン上で `kubectl proxy` を実行して API サーバーと通信させれば良い

#### Running inside a container even during development

* 開発中にどうしてもコンテナでアプリを実行しなければならない場合には、Docker ボリュームを介してローカルファイルシステムをマウントすることで毎回イメージを作成しなくても済む
* コンテナを再起動すれば新しいバージョンを実行できるし、アプリでホットデプロイがサポートされていればその必要すらない

### 17.5.2. Using Minikube in development

* 開発環境で Kubernetes で動かした場合の挙動を確認したい場合は　Minikube を使えばよい。

#### Mounting local files into the minikube VM and then into your containers

* ローカルのファイルを Kubernetes クラスタ内のアプリで使いたい場合は、
  * `minikube mount` でローカルファイルシステムを Minikube VM にマウント
  * hostPath を指定してコンテナにマウント

#### Using the Docker daemon inside the minikube VM to build your images

* アプリを更新するたびにコンテナイメージを構築しでデプロイしたい場合には、Minikube VM 内の Docker デーモンを使えば良い
* `eval $(minikube docker-env)` を実行すれば必要な設定が行われる
* Minikube VM 内でイメージがビルドされるので、リポジトリに push する必要はなくそのまま使える

#### Building images locally and copying them over to the minikube VM directly

* `docker save <image> | （eval $(minikube docker-env) && docker load)` でローカルのイメージを Minikube VM にコピー可能

### 17.5.3. Versioning and auto-deploying resource manifests

### 17.5.4. Introducing Ksonnet as an alternative to writing YAML/JSON manifests

### 17.5.5. Employing Continuous Integration and Continuous Delivery (CI/CD)
